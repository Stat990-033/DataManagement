{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing R data frames into Julia\n",
    "\n",
    "Many [R](http://www.R-project.org) packages provide data used to illustrate and to test functions and methods in the package.  The [RCall package](https://github.com/JuliaStats/RCall.jl) for [Julia](http://julialang.org), in conjunction with the [DataFrames package](https://github.com/JuliaStats/DataFrames.jl) provides for importing an R `data.frame` object as a Julia `DataFrame`, preserving much of the metadata.  In particular, columns that are `factor` or `ordered` objects in R become `PooledDataArray` objects in Julia.\n",
    "\n",
    "Because Julia has a richer type system than does R it is at times worthwhile modifying the types of the columns of the columns in Julia before saving the `DataFrame`.  Thus we explicitly import the [DataArrays package](https://github.org/JuliaStats/DataArrays.jl) in addition to [DataFrames](https://github.org/JuliaStats/DataArrays.jl).\n",
    "\n",
    "The Julia `DataFrame`s are saved in the `JLD` format provided by the [HDF5 package](https://github.com/timholy/HDF5.jl). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using DataArrays, DataFrames, HDF5, JLD, RCall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and examining an R data frame\n",
    "\n",
    "Attaching the [RCall package](https://github.com/JuliaStats/RCall.jl) initializes an embedded R process and provides methods for the `DataFrame` generic with `ASCIIString` or `Symbol` arguments.\n",
    "\n",
    "There are two approaches to accessing data from a particular package:\n",
    "   - use the fully qualified name (as a string)\n",
    "   - execute a call to the R function `library` and use the unqualified name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame  73421 observations of 7 variables\n",
      "  s: PooledDataArray{ASCIIString,Uint16,1}(73421) ASCIIString[\"1\",\"1\",\"1\",\"1\"]\n",
      "  d: PooledDataArray{ASCIIString,Uint16,1}(73421) ASCIIString[\"1002\",\"1050\",\"1582\",\"2050\"]\n",
      "  studage: PooledDataArray{ASCIIString,Uint8,1}(73421) ASCIIString[\"2\",\"2\",\"2\",\"2\"]\n",
      "  lectage: PooledDataArray{ASCIIString,Uint8,1}(73421) ASCIIString[\"2\",\"1\",\"2\",\"2\"]\n",
      "  service: PooledDataArray{ASCIIString,Uint8,1}(73421) ASCIIString[\"0\",\"1\",\"0\",\"1\"]\n",
      "  dept: PooledDataArray{ASCIIString,Uint8,1}(73421) ASCIIString[\"2\",\"6\",\"2\",\"3\"]\n",
      "  y: DataArray{Int32,1}(73421) Int32[5,2,5,3]\n"
     ]
    }
   ],
   "source": [
    "inst = DataFrame(\"lme4::InstEval\"); # fully qualified name\n",
    "dump(inst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `dump` generic is similar too (but less fully featured than) R's `str` function.  The data from the R `InstEval` object have been copied to Julia storage so there will not be a conflict between R's memory management and Julia's memory management.\n",
    "\n",
    "The alternative approach is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: Matrix\n",
      "\n",
      "Attaching package: ‘Matrix’\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    crossprod, tcrossprod\n",
      "\n",
      "Loading required package: Rcpp\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><tr><th></th><th>s</th><th>d</th><th>studage</th><th>lectage</th><th>service</th><th>dept</th><th>y</th></tr><tr><th>1</th><td>1</td><td>1002</td><td>2</td><td>2</td><td>0</td><td>2</td><td>5</td></tr><tr><th>2</th><td>1</td><td>1050</td><td>2</td><td>1</td><td>1</td><td>6</td><td>2</td></tr><tr><th>3</th><td>1</td><td>1582</td><td>2</td><td>2</td><td>0</td><td>2</td><td>5</td></tr><tr><th>4</th><td>1</td><td>2050</td><td>2</td><td>2</td><td>1</td><td>3</td><td>3</td></tr><tr><th>5</th><td>2</td><td>115</td><td>2</td><td>1</td><td>0</td><td>5</td><td>2</td></tr><tr><th>6</th><td>2</td><td>756</td><td>2</td><td>1</td><td>0</td><td>5</td><td>4</td></tr><tr><th>7</th><td>3</td><td>7</td><td>2</td><td>1</td><td>1</td><td>11</td><td>4</td></tr><tr><th>8</th><td>3</td><td>13</td><td>2</td><td>1</td><td>0</td><td>10</td><td>5</td></tr><tr><th>9</th><td>3</td><td>36</td><td>2</td><td>1</td><td>0</td><td>10</td><td>5</td></tr><tr><th>10</th><td>3</td><td>140</td><td>2</td><td>1</td><td>0</td><td>10</td><td>4</td></tr><tr><th>11</th><td>3</td><td>409</td><td>2</td><td>2</td><td>0</td><td>10</td><td>4</td></tr><tr><th>12</th><td>3</td><td>444</td><td>2</td><td>2</td><td>0</td><td>10</td><td>4</td></tr><tr><th>13</th><td>3</td><td>494</td><td>2</td><td>1</td><td>1</td><td>9</td><td>4</td></tr><tr><th>14</th><td>3</td><td>625</td><td>2</td><td>2</td><td>0</td><td>10</td><td>3</td></tr><tr><th>15</th><td>3</td><td>696</td><td>2</td><td>2</td><td>1</td><td>9</td><td>2</td></tr><tr><th>16</th><td>3</td><td>1056</td><td>2</td><td>2</td><td>1</td><td>8</td><td>4</td></tr><tr><th>17</th><td>3</td><td>1437</td><td>2</td><td>1</td><td>0</td><td>10</td><td>4</td></tr><tr><th>18</th><td>3</td><td>1917</td><td>2</td><td>1</td><td>0</td><td>10</td><td>5</td></tr><tr><th>19</th><td>3</td><td>1936</td><td>2</td><td>1</td><td>0</td><td>10</td><td>2</td></tr><tr><th>20</th><td>3</td><td>2058</td><td>2</td><td>1</td><td>0</td><td>10</td><td>3</td></tr><tr><th>21</th><td>4</td><td>17</td><td>2</td><td>2</td><td>0</td><td>2</td><td>4</td></tr><tr><th>22</th><td>4</td><td>70</td><td>2</td><td>1</td><td>1</td><td>11</td><td>5</td></tr><tr><th>23</th><td>4</td><td>501</td><td>2</td><td>1</td><td>0</td><td>2</td><td>5</td></tr><tr><th>24</th><td>4</td><td>1161</td><td>2</td><td>1</td><td>1</td><td>11</td><td>3</td></tr><tr><th>25</th><td>4</td><td>1323</td><td>2</td><td>1</td><td>0</td><td>2</td><td>4</td></tr><tr><th>26</th><td>4</td><td>1349</td><td>2</td><td>2</td><td>0</td><td>2</td><td>5</td></tr><tr><th>27</th><td>4</td><td>1361</td><td>2</td><td>1</td><td>0</td><td>2</td><td>4</td></tr><tr><th>28</th><td>4</td><td>1564</td><td>2</td><td>2</td><td>0</td><td>2</td><td>3</td></tr><tr><th>29</th><td>5</td><td>115</td><td>2</td><td>1</td><td>0</td><td>5</td><td>4</td></tr><tr><th>30</th><td>5</td><td>536</td><td>2</td><td>1</td><td>0</td><td>5</td><td>4</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></table>"
      ],
      "text/plain": [
       "73421x7 DataFrame\n",
       "| Row   | s      | d      | studage | lectage | service | dept | y |\n",
       "|-------|--------|--------|---------|---------|---------|------|---|\n",
       "| 1     | \"1\"    | \"1002\" | \"2\"     | \"2\"     | \"0\"     | \"2\"  | 5 |\n",
       "| 2     | \"1\"    | \"1050\" | \"2\"     | \"1\"     | \"1\"     | \"6\"  | 2 |\n",
       "| 3     | \"1\"    | \"1582\" | \"2\"     | \"2\"     | \"0\"     | \"2\"  | 5 |\n",
       "| 4     | \"1\"    | \"2050\" | \"2\"     | \"2\"     | \"1\"     | \"3\"  | 3 |\n",
       "| 5     | \"2\"    | \"115\"  | \"2\"     | \"1\"     | \"0\"     | \"5\"  | 2 |\n",
       "| 6     | \"2\"    | \"756\"  | \"2\"     | \"1\"     | \"0\"     | \"5\"  | 4 |\n",
       "| 7     | \"3\"    | \"7\"    | \"2\"     | \"1\"     | \"1\"     | \"11\" | 4 |\n",
       "| 8     | \"3\"    | \"13\"   | \"2\"     | \"1\"     | \"0\"     | \"10\" | 5 |\n",
       "| 9     | \"3\"    | \"36\"   | \"2\"     | \"1\"     | \"0\"     | \"10\" | 5 |\n",
       "| 10    | \"3\"    | \"140\"  | \"2\"     | \"1\"     | \"0\"     | \"10\" | 4 |\n",
       "| 11    | \"3\"    | \"409\"  | \"2\"     | \"2\"     | \"0\"     | \"10\" | 4 |\n",
       "⋮\n",
       "| 73410 | \"2972\" | \"1056\" | \"4\"     | \"2\"     | \"1\"     | \"8\"  | 5 |\n",
       "| 73411 | \"2972\" | \"1106\" | \"4\"     | \"1\"     | \"1\"     | \"4\"  | 3 |\n",
       "| 73412 | \"2972\" | \"1203\" | \"4\"     | \"3\"     | \"1\"     | \"3\"  | 5 |\n",
       "| 73413 | \"2972\" | \"1722\" | \"4\"     | \"5\"     | \"1\"     | \"11\" | 5 |\n",
       "| 73414 | \"2972\" | \"1749\" | \"4\"     | \"1\"     | \"0\"     | \"10\" | 5 |\n",
       "| 73415 | \"2972\" | \"1780\" | \"4\"     | \"4\"     | \"1\"     | \"11\" | 3 |\n",
       "| 73416 | \"2972\" | \"1782\" | \"4\"     | \"4\"     | \"1\"     | \"4\"  | 5 |\n",
       "| 73417 | \"2972\" | \"2034\" | \"4\"     | \"1\"     | \"1\"     | \"6\"  | 3 |\n",
       "| 73418 | \"2972\" | \"2079\" | \"4\"     | \"3\"     | \"1\"     | \"11\" | 4 |\n",
       "| 73419 | \"2972\" | \"2084\" | \"4\"     | \"1\"     | \"0\"     | \"10\" | 5 |\n",
       "| 73420 | \"2972\" | \"2110\" | \"4\"     | \"2\"     | \"1\"     | \"4\"  | 1 |\n",
       "| 73421 | \"2972\" | \"2121\" | \"4\"     | \"2\"     | \"1\"     | \"2\"  | 3 |"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reval(\"library(lme4)\");\n",
    "inst = DataFrame(:InstEval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert numeric levels to numbers\n",
    "\n",
    "The type of many of the columns of `inst` is, e.g. `PooledDataArray{ASCIIString,Uint16,1}`.  This is like a `factor` object in R in that the values being represented are from a finite collection, called the `levels` in R and the `pool` in Julia.  Here the  type of the `pool` is `ASCIIString`.  The integer indices into the pool are stored here as `Uint16` - an unsigned 16-bit integer.  These are called the `refs` in Julia because they are the references to objects in the pool.  In R the only integer type is a 32-bit signed integer.\n",
    "\n",
    "The Julia `PooledDataArray` specifies the type of the pool, the type of the refs and the number of dimensions - 1 in this case.\n",
    "\n",
    "In R the levels are almost always converted to strings.  In Julia there is no need to use strings when short integers or single characters can be used instead.  Strings are powerful but there is a lot going on behind the scenes to make the implementation effective.  All the indirection can be avoided if the pool is a simple \"bitstype\" vector.\n",
    "\n",
    "First we convert the strings in the pool to integers then check the maximum to see what size of integer would be best to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array(Int64,(1128,)) [1,6,7,8,12,13,14,15,17,18  …  2143,2145,2146,2147,2149,2152,2153,2156,2157,2160]\n"
     ]
    }
   ],
   "source": [
    "dn = map(parseint, inst[:d].pool);\n",
    "dump(dn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of `dn` is computed by mapping the `parseint` function to the pool of the `s` column of the `inst` data frame.  Note that individual columns in a `DataFrame` are indexed by name as a `Symbol` and that fields of a compound type like `PooledDataArray` are extracted with the `.` infix operator (similar to C, C++, ...).\n",
    "\n",
    "Because the pool vector is not very long we could leave it as 64-bit integers but, for storage, it is better to use 32-bit or 16-bit integers in this case.\n",
    "\n",
    "One way to create the 16-bit integers is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array(Int16,(1128,)) Int16[1,6,7,8,12,13,14,15,17,18  …  2143,2145,2146,2147,2149,2152,2153,2156,2157,2160]\n"
     ]
    }
   ],
   "source": [
    "dump(convert(Vector{Int16}, dn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative is to create the 16-bit integers by parsing the strings as 16-bit integers when creating `dn`.  As this involves using a non-default integer type, calling `map` gets more complicated.  The alternative is to use a _comprehension_ with generates an array by applying a function form to elements of an _iterator_.  It looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array(Int16,(1128,)) Int16[1,6,7,8,12,13,14,15,17,18  …  2143,2145,2146,2147,2149,2152,2153,2156,2157,2160]\n"
     ]
    }
   ],
   "source": [
    "dn = [parseint(Int16,x) for x in inst[:d].pool];\n",
    "dump(dn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We construct the new `PooledDataArray` with `setlevels`. It happens that the methods for `setlevels` don't allow changing the type of the pool, but we can easily construct such a method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "setlevels (generic function with 3 methods)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function DataArrays.setlevels(v::PooledDataArray,l::AbstractVector)\n",
    "    length(l) == length(v.pool) || throw(DimensionMismatch(\"\"))\n",
    "    PooledDataArray(DataArrays.RefArray(v.refs),l)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame  73421 observations of 7 variables\n",
      "  s: PooledDataArray{Int16,Uint16,1}(73421) Int16[1,1,1,1]\n",
      "  d: PooledDataArray{Int16,Uint16,1}(73421) Int16[1002,1050,1582,2050]\n",
      "  studage: PooledDataArray{Int8,Uint8,1}(73421) Int8[2,2,2,2]\n",
      "  lectage: PooledDataArray{Int8,Uint8,1}(73421) Int8[2,1,2,2]\n",
      "  service: PooledDataArray{Char,Uint8,1}(73421) Char['N','Y','N','Y']\n",
      "  dept: PooledDataArray{Int8,Uint8,1}(73421) Int8[2,6,2,3]\n",
      "  y: DataArray{Int8,1}(73421) Int8[5,2,5,3]\n"
     ]
    }
   ],
   "source": [
    "inst[:d] = setlevels(inst[:d], dn);\n",
    "inst[:s] = setlevels(inst[:s],\n",
    "    [parseint(Int16,x) for x in inst[:s].pool])\n",
    "inst[:studage] = setlevels(inst[:studage],\n",
    "    [parseint(Int8,x) for x in inst[:studage].pool]);\n",
    "inst[:lectage] = setlevels(inst[:lectage],\n",
    "    [parseint(Int8,x) for x in inst[:lectage].pool]);\n",
    "inst[:service] = setlevels(inst[:service], ['N','Y']);\n",
    "inst[:dept] = setlevels(inst[:dept],\n",
    "[parseint(Int8,x) for x in inst[:dept].pool])\n",
    "inst[:y] = convert(Vector{Int8},inst[:y]);\n",
    "dump(inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><tr><th></th><th>s</th><th>d</th><th>studage</th><th>lectage</th><th>service</th><th>dept</th><th>y</th></tr><tr><th>1</th><td>1</td><td>1002</td><td>2</td><td>2</td><td>N</td><td>2</td><td>5</td></tr><tr><th>2</th><td>1</td><td>1050</td><td>2</td><td>1</td><td>Y</td><td>6</td><td>2</td></tr><tr><th>3</th><td>1</td><td>1582</td><td>2</td><td>2</td><td>N</td><td>2</td><td>5</td></tr><tr><th>4</th><td>1</td><td>2050</td><td>2</td><td>2</td><td>Y</td><td>3</td><td>3</td></tr><tr><th>5</th><td>2</td><td>115</td><td>2</td><td>1</td><td>N</td><td>5</td><td>2</td></tr><tr><th>6</th><td>2</td><td>756</td><td>2</td><td>1</td><td>N</td><td>5</td><td>4</td></tr><tr><th>7</th><td>3</td><td>7</td><td>2</td><td>1</td><td>Y</td><td>11</td><td>4</td></tr><tr><th>8</th><td>3</td><td>13</td><td>2</td><td>1</td><td>N</td><td>10</td><td>5</td></tr><tr><th>9</th><td>3</td><td>36</td><td>2</td><td>1</td><td>N</td><td>10</td><td>5</td></tr><tr><th>10</th><td>3</td><td>140</td><td>2</td><td>1</td><td>N</td><td>10</td><td>4</td></tr></table>"
      ],
      "text/plain": [
       "10x7 DataFrame\n",
       "| Row | s | d    | studage | lectage | service | dept | y |\n",
       "|-----|---|------|---------|---------|---------|------|---|\n",
       "| 1   | 1 | 1002 | 2       | 2       | 'N'     | 2    | 5 |\n",
       "| 2   | 1 | 1050 | 2       | 1       | 'Y'     | 6    | 2 |\n",
       "| 3   | 1 | 1582 | 2       | 2       | 'N'     | 2    | 5 |\n",
       "| 4   | 1 | 2050 | 2       | 2       | 'Y'     | 3    | 3 |\n",
       "| 5   | 2 | 115  | 2       | 1       | 'N'     | 5    | 2 |\n",
       "| 6   | 2 | 756  | 2       | 1       | 'N'     | 5    | 4 |\n",
       "| 7   | 3 | 7    | 2       | 1       | 'Y'     | 11   | 4 |\n",
       "| 8   | 3 | 13   | 2       | 1       | 'N'     | 10   | 5 |\n",
       "| 9   | 3 | 36   | 2       | 1       | 'N'     | 10   | 5 |\n",
       "| 10  | 3 | 140  | 2       | 1       | 'N'     | 10   | 4 |"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head(inst,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving a DataFrame in JLD format.\n",
    "\n",
    "The JLD format is based on the [HDF5 format](http://www.hdfgroup.org/HDF5/), which is accessible from many languages and command line tools.  The implementation in Julia allows for compression of the data using [Blosc](http://www.blosc.org) but there is a trade-off between smaller data files using Blosc and the ability to _memory-map_ the data when reading it.\n",
    "\n",
    "Saving the data without compression is straightforward.  There is a `@save` macro to do this.  There is also a `save` function.  The macro allows access to both the name and the value of the object to be saved with a single argument whereas both the name and a quoted string must be given as arguments in the call to the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@save \"inst.jld\" inst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run the shell programs `h5ls` and `h5stat` to examine the file just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_refs                    Group\n",
      "_require                 Dataset {NULL}\n",
      "_types                   Group\n",
      "inst                     Dataset {SCALAR}\n"
     ]
    }
   ],
   "source": [
    "; h5ls inst.jld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: inst.jld\n",
      "File information\n",
      "\t# of unique groups: 3\n",
      "\t# of unique datasets: 30\n",
      "\t# of unique named datatypes: 10\n",
      "\t# of unique links: 0\n",
      "\t# of unique other: 0\n",
      "\tMax. # of links to object: 4\n",
      "\tMax. # of objects in group: 28\n",
      "Dataset dimension information:\n",
      "\tMax. rank of datasets: 1\n",
      "\tDataset ranks:\n",
      "\t\t# of dataset with rank 0: 12\n",
      "\t\t# of dataset with rank 1: 18\n",
      "1-D Dataset information:\n",
      "\tMax. dimension size of 1-D datasets: 73421\n",
      "\tSmall 1-D datasets (with dimension sizes 0 to 9):\n",
      "\t\t# of datasets with dimension sizes 2: 1\n",
      "\t\t# of datasets with dimension sizes 4: 1\n",
      "\t\t# of datasets with dimension sizes 6: 1\n",
      "\t\t# of datasets with dimension sizes 7: 4\n",
      "\t\tTotal # of small datasets: 7\n",
      "\t1-D Dataset dimension bins:\n",
      "\t\t# of datasets with dimension size 1 - 9: 7\n",
      "\t\t# of datasets with dimension size 10 - 99: 1\n",
      "\t\t# of datasets with dimension size 1000 - 9999: 3\n",
      "\t\t# of datasets with dimension size 10000 - 99999: 7\n",
      "\t\tTotal # of datasets: 18\n",
      "Dataset storage information:\n",
      "\tTotal raw data size: 678725\n",
      "\tTotal external raw data size: 0\n",
      "Dataset layout information:\n",
      "\tDataset layout counts[COMPACT]: 22\n",
      "\tDataset layout counts[CONTIG]: 8\n",
      "\tDataset layout counts[CHUNKED]: 0\n",
      "\tNumber of external files : 0\n",
      "Dataset filters information:\n",
      "\tNumber of datasets with:\n",
      "\t\tNO filter: 30\n",
      "\t\tGZIP filter: 0\n",
      "\t\tSHUFFLE filter: 0\n",
      "\t\tFLETCHER32 filter: 0\n",
      "\t\tSZIP filter: 0\n",
      "\t\tNBIT filter: 0\n",
      "\t\tSCALEOFFSET filter: 0\n",
      "\t\tUSER-DEFINED filter: 0\n"
     ]
    }
   ],
   "source": [
    "; h5stat -f -d inst.jld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The large number of HDF5 datasets being stored in the file reflects the fact that each column and its refs and pool members are considered separate datasets in the HDF5 terminology.\n",
    "\n",
    "The alternative approach compressing the data requires using the function `save`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save(\"inst1.jld\", \"inst\", inst; compress=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 bates bates  24832 Apr 28 12:48 cake.jld\n",
      "-rw-rw-r-- 1 bates bates 352807 Apr 28 13:17 inst1.jld\n",
      "-rw-rw-r-- 1 bates bates 700469 Apr 28 13:17 inst.jld\n",
      "-rw-rw-r-- 1 bates bates  19120 Apr 28 13:14 pastes.jld\n"
     ]
    }
   ],
   "source": [
    "; ls -l *.jld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: inst1.jld\n",
      "File information\n",
      "\t# of unique groups: 3\n",
      "\t# of unique datasets: 30\n",
      "\t# of unique named datatypes: 10\n",
      "\t# of unique links: 0\n",
      "\t# of unique other: 0\n",
      "\tMax. # of links to object: 4\n",
      "\tMax. # of objects in group: 28\n",
      "Dataset dimension information:\n",
      "\tMax. rank of datasets: 1\n",
      "\tDataset ranks:\n",
      "\t\t# of dataset with rank 0: 12\n",
      "\t\t# of dataset with rank 1: 18\n",
      "1-D Dataset information:\n",
      "\tMax. dimension size of 1-D datasets: 73421\n",
      "\tSmall 1-D datasets (with dimension sizes 0 to 9):\n",
      "\t\t# of datasets with dimension sizes 2: 1\n",
      "\t\t# of datasets with dimension sizes 4: 1\n",
      "\t\t# of datasets with dimension sizes 6: 1\n",
      "\t\t# of datasets with dimension sizes 7: 4\n",
      "\t\tTotal # of small datasets: 7\n",
      "\t1-D Dataset dimension bins:\n",
      "\t\t# of datasets with dimension size 1 - 9: 7\n",
      "\t\t# of datasets with dimension size 10 - 99: 1\n",
      "\t\t# of datasets with dimension size 1000 - 9999: 3\n",
      "\t\t# of datasets with dimension size 10000 - 99999: 7\n",
      "\t\tTotal # of datasets: 18\n",
      "Dataset storage information:\n",
      "\tTotal raw data size: 314059\n",
      "\tTotal external raw data size: 0\n",
      "Dataset layout information:\n",
      "\tDataset layout counts[COMPACT]: 22\n",
      "\tDataset layout counts[CONTIG]: 0\n",
      "\tDataset layout counts[CHUNKED]: 8\n",
      "\tNumber of external files : 0\n",
      "Dataset filters information:\n",
      "\tNumber of datasets with:\n",
      "\t\tNO filter: 22\n",
      "\t\tGZIP filter: 0\n",
      "\t\tSHUFFLE filter: 0\n",
      "\t\tFLETCHER32 filter: 0\n",
      "\t\tSZIP filter: 0\n",
      "\t\tNBIT filter: 0\n",
      "\t\tSCALEOFFSET filter: 0\n",
      "\t\tUSER-DEFINED filter: 8\n"
     ]
    }
   ],
   "source": [
    "; h5stat -d -f inst1.jld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the file with compressed columns is about half the size of the file without compression.\n",
    "\n",
    "## Single-character levels as characters\n",
    "\n",
    "Often the levels of the factors in a dataset are single characters.  These can be converted to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame  270 observations of 5 variables\n",
      "  replicate: PooledDataArray{ASCIIString,Uint8,1}(270) ASCIIString[\"1\",\"1\",\"1\",\"1\"]\n",
      "  recipe: PooledDataArray{ASCIIString,Uint8,1}(270) ASCIIString[\"A\",\"A\",\"A\",\"A\"]\n",
      "  temperature: PooledDataArray{ASCIIString,Uint8,1}(270) ASCIIString[\"175\",\"185\",\"195\",\"205\"]\n",
      "  angle: DataArray{Int32,1}(270) Int32[42,46,47,39]\n",
      "  temp: DataArray{Float64,1}(270) [175.0,185.0,195.0,205.0]\n"
     ]
    }
   ],
   "source": [
    "cake = DataFrame(\"lme4::cake\");\n",
    "dump(cake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASCIIString[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\"]"
     ]
    }
   ],
   "source": [
    "show(cake[:replicate].pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASCIIString[\"A\",\"B\",\"C\"]"
     ]
    }
   ],
   "source": [
    "cake[:replicate] = setlevels(cake[:replicate],\n",
    "    [parseint(Int8,x) for x in cake[:replicate].pool]);\n",
    "\n",
    "show(cake[:recipe].pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame  270 observations of 5 variables\n",
      "  replicate: PooledDataArray{Int8,Uint8,1}(270) Int8[1,1,1,1]\n",
      "  recipe: PooledDataArray{Char,Uint8,1}(270) Char['A','A','A','A']\n",
      "  temperature: PooledDataArray{Int16,Uint8,1}(270) Int16[175,185,195,205]\n",
      "  angle: DataArray{Int32,1}(270) Int32[42,46,47,39]\n",
      "  temp: DataArray{Float64,1}(270) [175.0,185.0,195.0,205.0]\n"
     ]
    }
   ],
   "source": [
    "cake[:recipe] = \n",
    "setlevels(cake[:recipe],[x[1]::Char for x in cake[:recipe].pool]);\n",
    "cake[:temperature] = setlevels(cake[:temperature],\n",
    "    [parseint(Int16,x) for x in cake[:temperature].pool]);\n",
    "dump(cake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save(\"cake.jld\", \"cake\", cake; compress=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: cake.jld\n",
      "File information\n",
      "\t# of unique groups: 3\n",
      "\t# of unique datasets: 25\n",
      "\t# of unique named datatypes: 11\n",
      "\t# of unique links: 0\n",
      "\t# of unique other: 0\n",
      "\tMax. # of links to object: 3\n",
      "\tMax. # of objects in group: 23\n",
      "Dataset dimension information:\n",
      "\tMax. rank of datasets: 1\n",
      "\tDataset ranks:\n",
      "\t\t# of dataset with rank 0: 11\n",
      "\t\t# of dataset with rank 1: 14\n",
      "1-D Dataset information:\n",
      "\tMax. dimension size of 1-D datasets: 270\n",
      "\tSmall 1-D datasets (with dimension sizes 0 to 9):\n",
      "\t\t# of datasets with dimension sizes 3: 1\n",
      "\t\t# of datasets with dimension sizes 5: 6\n",
      "\t\t# of datasets with dimension sizes 6: 1\n",
      "\t\tTotal # of small datasets: 8\n",
      "\t1-D Dataset dimension bins:\n",
      "\t\t# of datasets with dimension size 1 - 9: 8\n",
      "\t\t# of datasets with dimension size 10 - 99: 1\n",
      "\t\t# of datasets with dimension size 100 - 999: 5\n",
      "\t\tTotal # of datasets: 14\n",
      "Dataset storage information:\n",
      "\tTotal raw data size: 4585\n",
      "\tTotal external raw data size: 0\n",
      "Dataset layout information:\n",
      "\tDataset layout counts[COMPACT]: 25\n",
      "\tDataset layout counts[CONTIG]: 0\n",
      "\tDataset layout counts[CHUNKED]: 0\n",
      "\tNumber of external files : 0\n",
      "Dataset filters information:\n",
      "\tNumber of datasets with:\n",
      "\t\tNO filter: 25\n",
      "\t\tGZIP filter: 0\n",
      "\t\tSHUFFLE filter: 0\n",
      "\t\tFLETCHER32 filter: 0\n",
      "\t\tSZIP filter: 0\n",
      "\t\tNBIT filter: 0\n",
      "\t\tSCALEOFFSET filter: 0\n",
      "\t\tUSER-DEFINED filter: 0\n"
     ]
    }
   ],
   "source": [
    "; h5stat -d -f cake.jld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there has been no compression of any of the elements.  This is because the vector lengths must be above a threshold before it becomes worthwhile compressing the contents.\n",
    "\n",
    "I just noticed that the same information is being stored in different forms in the `temperature` and `temp` columns.  That should be fixed but it is a minor fix.\n",
    "\n",
    "## A more general method for setting new levels.\n",
    "\n",
    "The `setlevels` method given above does save some typing but it is still rather tedious to use.  We create a method that takes the `DataFrame`, the column name and a function to apply to get the new levels.  In this case, the appropriate generic function name is `setlevels!` because the method will be _mutating_.  That is, it changes one or more of its arguments - here it will be the data frame.\n",
    "\n",
    "It is a convention that the names of mutating functions end in `!`.  That character has no semantic meaning; it is just part of the name.  The convention is to alert the user that extra caution is needed when using such a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "setlevels! (generic function with 4 methods)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function DataArrays.setlevels!(fr::DataFrame, s::Symbol, func::Function)\n",
    "    s ∈ names(fr) && isa(fr[s], PooledDataArray) || \n",
    "        error(\"The symbol s must name a PooledDataArray column of fr\")\n",
    "    fr[s] = setlevels(fr[s], map(func, fr[s].pool))\n",
    "    fr\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame  60 observations of 4 variables\n",
      "  strength: DataArray{Float64,1}(60) [62.8,62.6,60.1,62.3]\n",
      "  batch: PooledDataArray{ASCIIString,Uint8,1}(60) ASCIIString[\"A\",\"A\",\"A\",\"A\"]\n",
      "  cask: PooledDataArray{ASCIIString,Uint8,1}(60) ASCIIString[\"a\",\"a\",\"b\",\"b\"]\n",
      "  sample: PooledDataArray{ASCIIString,Uint8,1}(60) ASCIIString[\"A:a\",\"A:a\",\"A:b\",\"A:b\"]\n"
     ]
    }
   ],
   "source": [
    "pastes = DataFrame(\"lme4::Pastes\");\n",
    "dump(pastes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "char1 (generic function with 1 method)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char1(s::ASCIIString) = s[1]   # extract first character of a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame  60 observations of 4 variables\n",
      "  strength: DataArray{Float64,1}(60) [62.8,62.6,60.1,62.3]\n",
      "  batch: PooledDataArray{Char,Uint8,1}(60) Char['A','A','A','A']\n",
      "  cask: PooledDataArray{Char,Uint8,1}(60) Char['a','a','b','b']\n",
      "  sample: PooledDataArray{ASCIIString,Uint8,1}(60) ASCIIString[\"A:a\",\"A:a\",\"A:b\",\"A:b\"]\n"
     ]
    }
   ],
   "source": [
    "setlevels!(pastes, :batch, char1);\n",
    "setlevels!(pastes, :cask, char1);\n",
    "dump(pastes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@save \"pastes.jld\" pastes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: pastes.jld\n",
      "File information\n",
      "\t# of unique groups: 3\n",
      "\t# of unique datasets: 21\n",
      "\t# of unique named datatypes: 9\n",
      "\t# of unique links: 0\n",
      "\t# of unique other: 0\n",
      "\tMax. # of links to object: 3\n",
      "\tMax. # of objects in group: 19\n",
      "Dataset dimension information:\n",
      "\tMax. rank of datasets: 1\n",
      "\tDataset ranks:\n",
      "\t\t# of dataset with rank 0: 9\n",
      "\t\t# of dataset with rank 1: 12\n",
      "1-D Dataset information:\n",
      "\tMax. dimension size of 1-D datasets: 60\n",
      "\tSmall 1-D datasets (with dimension sizes 0 to 9):\n",
      "\t\t# of datasets with dimension sizes 1: 1\n",
      "\t\t# of datasets with dimension sizes 3: 1\n",
      "\t\t# of datasets with dimension sizes 4: 4\n",
      "\t\tTotal # of small datasets: 6\n",
      "\t1-D Dataset dimension bins:\n",
      "\t\t# of datasets with dimension size 1 - 9: 6\n",
      "\t\t# of datasets with dimension size 10 - 99: 6\n",
      "\t\tTotal # of datasets: 12\n",
      "Dataset storage information:\n",
      "\tTotal raw data size: 1528\n",
      "\tTotal external raw data size: 0\n",
      "Dataset layout information:\n",
      "\tDataset layout counts[COMPACT]: 21\n",
      "\tDataset layout counts[CONTIG]: 0\n",
      "\tDataset layout counts[CHUNKED]: 0\n",
      "\tNumber of external files : 0\n",
      "Dataset filters information:\n",
      "\tNumber of datasets with:\n",
      "\t\tNO filter: 21\n",
      "\t\tGZIP filter: 0\n",
      "\t\tSHUFFLE filter: 0\n",
      "\t\tFLETCHER32 filter: 0\n",
      "\t\tSZIP filter: 0\n",
      "\t\tNBIT filter: 0\n",
      "\t\tSCALEOFFSET filter: 0\n",
      "\t\tUSER-DEFINED filter: 0\n"
     ]
    }
   ],
   "source": [
    "; h5stat -d -f pastes.jld"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.3.7",
   "language": "julia",
   "name": "julia 0.3"
  },
  "language_info": {
   "name": "julia",
   "version": "0.3.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
